{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0da19126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "fa5ffdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "default=pd.read_csv(\"../datasets/Default.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "a28329b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   default  student      balance        income\n",
       "0        0        0   729.526495  44361.625074\n",
       "1        0        1   817.180407  12106.134700\n",
       "2        0        0  1073.549164  31767.138947\n",
       "3        0        0   529.250605  35704.493935\n",
       "4        0        0   785.655883  38463.495879"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "d3408c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "default['default']=default['default'].apply(lambda x: 0 if x=='No' else 1)\n",
    "default['student']=default['student'].apply(lambda x: 1 if x=='Yes' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3237c69b",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ae71f",
   "metadata": {},
   "source": [
    "Note that linear regression won't work on categorical response. Main reasons are (1) the difference between one category to another may not be fixed (2) linear regression outputs value outside of $[0,1]$, making it hard to interpret as probabilities.\n",
    "\n",
    "Thus, we use a logistic function (aka sigmoid function) to squeeze output values into a valid probability \n",
    "distribution\n",
    "\n",
    "$\\sigma(z_i)=\\frac{1}{1+e^{-z_i}}$ where $z_i=\\beta_{0}+\\beta_{1}x_i$\n",
    "\n",
    "Then $\\hat{p}_i=P(y=1|x_i)$\n",
    "\n",
    "We use Maximum Likelihood Estimate (MLE) to estimate the parameters\n",
    "\n",
    "$L(\\beta_0,\\beta_1)=\\prod_{i=1}^{n}\\hat{p}_i^{y_i}(1-\\hat{p}_i)^{1-y_i}$\n",
    "\n",
    "Then the log-likelihood function becomes\n",
    "\n",
    "$l(\\beta_0,\\beta_1)=\\sum_{i=1}^{n}y_ilog(\\hat{p}_i)+(1-y_i)log(1-\\hat{p}_i)$\n",
    "\n",
    "With some algebra and partial derivatives, we arrive at\n",
    "\n",
    "$\\frac{dl(\\beta_0,\\beta_1)}{d\\beta_0}=\\sum_{i=1}^{n}(y_i-\\hat{p}_i)$ and\n",
    "$\\frac{dl(\\beta_0,\\beta_1)}{d\\beta_1}=\\sum_{i=1}^{n}(y_i-\\hat{p}_i)x_i$\n",
    "\n",
    "Now, update the gradient as follows:\n",
    "\n",
    "$\\beta_0=\\beta_0+\\eta\\sum_{i=1}^{n}(y_i-\\hat{p}_i)$\n",
    "\n",
    "$\\beta_1=\\beta_1+\\eta\\sum_{i=1}^{n}(y_i-\\hat{p}_i)x_i$, where $\\eta$ is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "195c7929",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=default['balance'].values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "08d3b31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - np.mean(X)) / np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e997be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=default['default'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "80f26f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000,))"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "deb137e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0 = np.random.normal(0, 0.01)\n",
    "beta_1 = np.random.normal(0, 0.01)\n",
    "lr=0.0001\n",
    "n_iter=10000\n",
    "tol=1e-6\n",
    "prev_loss=float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "01b4e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(n_iter):\n",
    "    p_hat=1/(1+np.exp(-(beta_0+beta_1*X)))\n",
    "    \n",
    "    loss = -np.mean(y * np.log(p_hat + 1e-15) + (1 - y) * np.log(1 - p_hat + 1e-15))\n",
    "    # Check convergence\n",
    "    if abs(prev_loss - loss) < tol:\n",
    "        print(f\"Converged at iteration {i}, loss = {loss:.6f}\")\n",
    "        break\n",
    "    \n",
    "    beta_0+=lr*np.sum(y-p_hat)\n",
    "    beta_1+=lr*np.sum((y-p_hat) * X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "04e6f8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_0 from scratch: -6.05767351529054\n",
      "b_1 from scratch: 2.6597755249632526\n"
     ]
    }
   ],
   "source": [
    "print(\"b_0 from scratch:\",beta_0)\n",
    "print(\"b_1 from scratch:\",beta_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "a91e4595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "c4f93217",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "47290ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(penalty=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(penalty=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(penalty=None)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X.reshape(-1,1),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "34ea7d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_0 from sklearn: [-6.05769037]\n",
      "b_1 from sklearn: [[2.65978348]]\n"
     ]
    }
   ],
   "source": [
    "print(\"b_0 from sklearn:\",lr.intercept_)\n",
    "print(\"b_1 from sklearn:\",lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873a5a43",
   "metadata": {},
   "source": [
    "# Logistic Regression (Multiple Variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "970c9e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   default  student      balance        income\n",
       "0        0        0   729.526495  44361.625074\n",
       "1        0        1   817.180407  12106.134700\n",
       "2        0        0  1073.549164  31767.138947\n",
       "3        0        0   529.250605  35704.493935\n",
       "4        0        0   785.655883  38463.495879"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "fd62b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=default.drop('default',axis=1).values\n",
    "y=default['default'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "274cda27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 3), (10000,))"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape ,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "21993fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "X = np.hstack([np.ones((X.shape[0], 1)), X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "114ba1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=np.zeros(X.shape[1])  # one beta per feature, including intercept\n",
    "lr=0.0001\n",
    "n_iter=10000\n",
    "tol=1e-6\n",
    "prev_loss=float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "8b0606d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_iter):\n",
    "    z=X@beta\n",
    "    p_hat=1/(1+np.exp(-z))\n",
    "    loss = -np.mean(y * np.log(p_hat + 1e-15) + (1 - y) * np.log(1 - p_hat + 1e-15))\n",
    "    \n",
    "    # Check convergence\n",
    "    if abs(prev_loss - loss) < tol:\n",
    "        print(f\"Converged at iteration {i}, loss = {loss:.6f}\")\n",
    "        break\n",
    "    \n",
    "    grad = X.T@(y-p_hat)  # shape: (n_features + 1,)\n",
    "    beta += lr * grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "fbed34e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta from scratch: [-6.16565149 -0.29478268  2.77469481  0.04045401]\n"
     ]
    }
   ],
   "source": [
    "print(\"beta from scratch:\",beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "c29a2438",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty=None,fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "23702873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(fit_intercept=False, penalty=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(fit_intercept=False, penalty=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(fit_intercept=False, penalty=None)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "96ffc70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta from sklearn: [-6.1656557  -0.29478494  2.774699    0.04045078]\n"
     ]
    }
   ],
   "source": [
    "print(\"beta from sklearn:\",lr.coef_.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafb7e43",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be75a801",
   "metadata": {},
   "source": [
    "Recall when $y\\in\\{0,1\\}$, we have $P(y=1|X)=\\frac{1}{1+exp(-z)}$ where $z=X^T\\beta$\n",
    "\n",
    "Now suppose $y\\in\\{1,2,3,...,K\\}$ where $K>2$.\n",
    "\n",
    "Wen need to model a full probability distribution over K classes; that is, $P(y=k|X) \\text{ for each } k=1,...,K$.\n",
    "\n",
    "Softmax function comes into play \n",
    "\n",
    "$P(y=k|X)=\\frac{exp(X^T\\beta_k)}{\\sum_{j=1}^{k}exp(X^T\\beta_j)}$ and so for each $k$, we have $z_k=X^T\\beta_k$.\n",
    "\n",
    "Identifiability Problem:\n",
    "\n",
    "We instead model K-1 models to avoid redundancy. We are overestimating parameters because probabilities need to sum to 1.\n",
    "\n",
    "Without loss of generality,  use Kth class as the baseline model.\n",
    "\n",
    "Then $P(y=K|X)=\\frac{1}{1+\\sum_{j=1}^{K-1}exp(X^T\\beta_j)}$ and\n",
    "$P(y=k|X)=\\frac{exp(X^T\\beta_k)}{1+\\sum_{j=1}^{K-1}exp(X^T\\beta_j)}$ for each $k=1,...,K-1$\n",
    "\n",
    "Estimation Set-up:\n",
    "\n",
    "Given $X\\in\\mathbb{R}^{N\\times(P+1)}$\n",
    "\n",
    "$y\\in\\mathbb{R}^{N}$\n",
    "\n",
    "$B\\in\\mathbb{R}^{({P+1})\\times({K-1})}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "2bf97c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "carseats=pd.read_csv(\"../datasets/Carseats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "54f95475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>CompPrice</th>\n",
       "      <th>Income</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>ShelveLoc</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Urban</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.50</td>\n",
       "      <td>138</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>276</td>\n",
       "      <td>120</td>\n",
       "      <td>Bad</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.22</td>\n",
       "      <td>111</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>260</td>\n",
       "      <td>83</td>\n",
       "      <td>Good</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.06</td>\n",
       "      <td>113</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>269</td>\n",
       "      <td>80</td>\n",
       "      <td>Medium</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.40</td>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>97</td>\n",
       "      <td>Medium</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.15</td>\n",
       "      <td>141</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>340</td>\n",
       "      <td>128</td>\n",
       "      <td>Bad</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales  CompPrice  Income  Advertising  Population  Price ShelveLoc  Age  \\\n",
       "0   9.50        138      73           11         276    120       Bad   42   \n",
       "1  11.22        111      48           16         260     83      Good   65   \n",
       "2  10.06        113      35           10         269     80    Medium   59   \n",
       "3   7.40        117     100            4         466     97    Medium   55   \n",
       "4   4.15        141      64            3         340    128       Bad   38   \n",
       "\n",
       "   Education Urban   US  \n",
       "0         17   Yes  Yes  \n",
       "1         10   Yes  Yes  \n",
       "2         12   Yes  Yes  \n",
       "3         14   Yes  Yes  \n",
       "4         13   Yes   No  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carseats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "48c9700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "06bb74a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=carseats.drop(['ShelveLoc','Urban','US'],axis=1).values\n",
    "y=carseats['ShelveLoc'].astype('category').cat.codes.values #0:Bad 1:Good 3:Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "db81e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "B=np.zeros((X.shape[1],K-1))  # one beta per feature, including intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "60c8ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    logits_stable = logits - np.max(logits, axis=1, keepdims=True)  # stability trick\n",
    "    exp_logits = np.exp(logits_stable)\n",
    "    return exp_logits / np.sum(exp_logits, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "24571544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_and_gradient(X, y, B, K):\n",
    "    N = X.shape[0]\n",
    "    \n",
    "    # Forward pass\n",
    "    Z = X@B                   # shape: (N, K-1)\n",
    "    Z_full = np.hstack([Z, np.zeros((N, 1))])  # shape: (N, K)\n",
    "    probs = softmax(Z_full)      # shape: (N, K)\n",
    "\n",
    "    # Compute loss\n",
    "    correct_log_probs = -np.log(probs[np.arange(N), y] + 1e-9)\n",
    "    loss = np.mean(correct_log_probs)\n",
    "\n",
    "    # One-hot true labels\n",
    "    Y = one_hot(y, K)\n",
    "\n",
    "    # Gradient: only for first K-1 columns\n",
    "    grad = -(X.T @ (Y[:, :K-1] - probs[:, :K-1])) / N  # shape: (P+1, K-1)\n",
    "\n",
    "    return loss, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "df074dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, K, lr=0.1, epochs=10000):\n",
    "    N, P_plus1 = X.shape  # assume X already includes bias column\n",
    "    B = np.zeros((P_plus1, K - 1))  # initialize weights\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss, grad = compute_loss_and_gradient(X, y, B, K)\n",
    "        B -= lr * grad  # gradient descent update\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
    "\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "d83693b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 1.0986\n",
      "Epoch 100: Loss = 0.7714\n",
      "Epoch 200: Loss = 0.6714\n",
      "Epoch 300: Loss = 0.6142\n",
      "Epoch 400: Loss = 0.5756\n",
      "Epoch 500: Loss = 0.5474\n",
      "Epoch 600: Loss = 0.5258\n",
      "Epoch 700: Loss = 0.5088\n",
      "Epoch 800: Loss = 0.4949\n",
      "Epoch 900: Loss = 0.4834\n",
      "Epoch 1000: Loss = 0.4738\n",
      "Epoch 1100: Loss = 0.4655\n",
      "Epoch 1200: Loss = 0.4585\n",
      "Epoch 1300: Loss = 0.4523\n",
      "Epoch 1400: Loss = 0.4470\n",
      "Epoch 1500: Loss = 0.4422\n",
      "Epoch 1600: Loss = 0.4380\n",
      "Epoch 1700: Loss = 0.4343\n",
      "Epoch 1800: Loss = 0.4309\n",
      "Epoch 1900: Loss = 0.4279\n",
      "Epoch 2000: Loss = 0.4251\n",
      "Epoch 2100: Loss = 0.4226\n",
      "Epoch 2200: Loss = 0.4204\n",
      "Epoch 2300: Loss = 0.4183\n",
      "Epoch 2400: Loss = 0.4164\n",
      "Epoch 2500: Loss = 0.4147\n",
      "Epoch 2600: Loss = 0.4131\n",
      "Epoch 2700: Loss = 0.4116\n",
      "Epoch 2800: Loss = 0.4102\n",
      "Epoch 2900: Loss = 0.4089\n",
      "Epoch 3000: Loss = 0.4078\n",
      "Epoch 3100: Loss = 0.4067\n",
      "Epoch 3200: Loss = 0.4056\n",
      "Epoch 3300: Loss = 0.4047\n",
      "Epoch 3400: Loss = 0.4038\n",
      "Epoch 3500: Loss = 0.4030\n",
      "Epoch 3600: Loss = 0.4022\n",
      "Epoch 3700: Loss = 0.4014\n",
      "Epoch 3800: Loss = 0.4007\n",
      "Epoch 3900: Loss = 0.4001\n",
      "Epoch 4000: Loss = 0.3995\n",
      "Epoch 4100: Loss = 0.3989\n",
      "Epoch 4200: Loss = 0.3984\n",
      "Epoch 4300: Loss = 0.3978\n",
      "Epoch 4400: Loss = 0.3973\n",
      "Epoch 4500: Loss = 0.3969\n",
      "Epoch 4600: Loss = 0.3964\n",
      "Epoch 4700: Loss = 0.3960\n",
      "Epoch 4800: Loss = 0.3956\n",
      "Epoch 4900: Loss = 0.3953\n",
      "Epoch 5000: Loss = 0.3949\n",
      "Epoch 5100: Loss = 0.3946\n",
      "Epoch 5200: Loss = 0.3942\n",
      "Epoch 5300: Loss = 0.3939\n",
      "Epoch 5400: Loss = 0.3936\n",
      "Epoch 5500: Loss = 0.3934\n",
      "Epoch 5600: Loss = 0.3931\n",
      "Epoch 5700: Loss = 0.3928\n",
      "Epoch 5800: Loss = 0.3926\n",
      "Epoch 5900: Loss = 0.3923\n",
      "Epoch 6000: Loss = 0.3921\n",
      "Epoch 6100: Loss = 0.3919\n",
      "Epoch 6200: Loss = 0.3917\n",
      "Epoch 6300: Loss = 0.3915\n",
      "Epoch 6400: Loss = 0.3913\n",
      "Epoch 6500: Loss = 0.3911\n",
      "Epoch 6600: Loss = 0.3910\n",
      "Epoch 6700: Loss = 0.3908\n",
      "Epoch 6800: Loss = 0.3906\n",
      "Epoch 6900: Loss = 0.3905\n",
      "Epoch 7000: Loss = 0.3903\n",
      "Epoch 7100: Loss = 0.3902\n",
      "Epoch 7200: Loss = 0.3900\n",
      "Epoch 7300: Loss = 0.3899\n",
      "Epoch 7400: Loss = 0.3898\n",
      "Epoch 7500: Loss = 0.3897\n",
      "Epoch 7600: Loss = 0.3895\n",
      "Epoch 7700: Loss = 0.3894\n",
      "Epoch 7800: Loss = 0.3893\n",
      "Epoch 7900: Loss = 0.3892\n",
      "Epoch 8000: Loss = 0.3891\n",
      "Epoch 8100: Loss = 0.3890\n",
      "Epoch 8200: Loss = 0.3889\n",
      "Epoch 8300: Loss = 0.3888\n",
      "Epoch 8400: Loss = 0.3887\n",
      "Epoch 8500: Loss = 0.3886\n",
      "Epoch 8600: Loss = 0.3885\n",
      "Epoch 8700: Loss = 0.3885\n",
      "Epoch 8800: Loss = 0.3884\n",
      "Epoch 8900: Loss = 0.3883\n",
      "Epoch 9000: Loss = 0.3882\n",
      "Epoch 9100: Loss = 0.3882\n",
      "Epoch 9200: Loss = 0.3881\n",
      "Epoch 9300: Loss = 0.3880\n",
      "Epoch 9400: Loss = 0.3879\n",
      "Epoch 9500: Loss = 0.3879\n",
      "Epoch 9600: Loss = 0.3878\n",
      "Epoch 9700: Loss = 0.3878\n",
      "Epoch 9800: Loss = 0.3877\n",
      "Epoch 9900: Loss = 0.3876\n"
     ]
    }
   ],
   "source": [
    "B=train(X,y,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a4fbb704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, B):\n",
    "    Z = X@B\n",
    "    Z_full = np.hstack([Z, np.zeros((Z.shape[0], 1))])\n",
    "    probs = softmax(Z_full)\n",
    "    return np.argmax(probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "547e19b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.89416609, -3.85813226],\n",
       "       [-5.18990202,  6.71835592],\n",
       "       [ 2.54396455, -3.47180519],\n",
       "       [ 1.11203446, -0.77230472],\n",
       "       [ 1.34435925, -1.664928  ],\n",
       "       [ 0.17309442, -0.03255806],\n",
       "       [-4.17369657,  5.50344955],\n",
       "       [-1.546851  ,  1.71269739],\n",
       "       [-0.08941834,  0.05661568]])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "cea01bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLR from scratch: 0.84\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of MLR from scratch:\",accuracy_score(y,predict(X,B)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a9d37a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "2c1e29fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "28d36fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr= LogisticRegression(multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "9c5db737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(multi_class='multinomial')"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "42859ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLR with sklearn: 0.8375\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of MLR with sklearn:\",accuracy_score(y,mlr.predict(X)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
